{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/KennethMacBookPro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "##import numpy as np  \n",
    "#import matplotlib.pyplot as plt  \n",
    "#import seaborn as seabornInstance \n",
    "\n",
    "##from sklearn.model_selection import train_test_split \n",
    "##from sklearn import neighbors\n",
    "##from sklearn.metrics import mean_squared_error\n",
    "##from sklearn.metrics import mean_absolute_error\n",
    "##from sklearn.metrics import accuracy_score\n",
    "##from sklearn import metrics\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "##import gensim\n",
    "##from gensim.test.utils import get_tmpfile\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import ast\n",
    "import re\n",
    "\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import os\n",
    "#import dialogflow\n",
    "##import requests\n",
    "##import json\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "#%matplotlib inline\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/webhook', methods=['POST'])\n",
    "def webhook():\n",
    "    data = request.get_json(silent=True)   # get the incoming JSON structure\n",
    "    action = data['queryResult']['action'] # get the action name associated with the matched intent\n",
    "    \n",
    "    if (action == 'get_task'):\n",
    "        return get_tasks(data)\n",
    "    elif (action == 'get_task_simple'):\n",
    "        return get_tasks_quick(data)\n",
    "    else: None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tasks_quick(data):\n",
    "    outputContextData= data['queryResult']['outputContexts']\n",
    "    sentiment_text, affinity_modifiers, like_text, dislike_text=extract_data_simple(outputContextData)\n",
    "    \n",
    "    message_list= [sentiment_text, affinity_modifiers, like_text, dislike_text]\n",
    "    \n",
    "    rm=Recommender_Model()\n",
    "    reply=rm.query_recommendation_model(message_list)\n",
    "    \n",
    "    #for testing, comment out jsonify(reply)\n",
    "    return jsonify(reply)\n",
    "    #print (reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function extract the data from the fulfilment request.\n",
    "def extract_data_simple(outputContextData):\n",
    "    for i in range(len(outputContextData)):\n",
    "            \n",
    "        if 'ctx_like_text' in outputContextData[i]['name']:\n",
    "            like_text=outputContextData[i]['parameters']['like_text']\n",
    "            \n",
    "        if 'ctx_dislike_text' in outputContextData[i]['name']:\n",
    "            dislike_text=outputContextData[i]['parameters']['dislike_text']\n",
    "                \n",
    "            \n",
    "    sentiment_text='neutral, neutral, neutral' # return sentiment as neutral\n",
    "    \n",
    "    \n",
    "    affinity_modifiers=affinity_tester(5,5) #make the affinity neutral\n",
    "    \n",
    "    \n",
    "    return sentiment_text, affinity_modifiers, like_text, dislike_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tasks(data):\n",
    "    outputContextData= data['queryResult']['outputContexts']\n",
    "    sentiment_text, affinity_modifiers, like_text, dislike_text=extract_data(outputContextData)\n",
    "    \n",
    "    message_list= [sentiment_text, affinity_modifiers, like_text, dislike_text]\n",
    "    \n",
    "    rm=Recommender_Model()\n",
    "    reply=rm.query_recommendation_model(message_list)\n",
    "    \n",
    "    #for testing, comment out jsonify(reply)\n",
    "    return jsonify(reply)\n",
    "    #print (reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function extract the data from the fulfilment request.\n",
    "def extract_data(outputContextData):\n",
    "    for i in range(len(outputContextData)):\n",
    "        if 'ctx_sentiment_text' in outputContextData[i]['name']:\n",
    "            sentiment_text_1=outputContextData[i]['parameters']['sentiment_text_1']\n",
    "            sentiment_text_2=outputContextData[i]['parameters']['sentiment_text_2']\n",
    "            sentiment_text_3=outputContextData[i]['parameters']['sentiment_text_3']\n",
    "            \n",
    "        if 'ctx_like_text' in outputContextData[i]['name']:\n",
    "            like_text=outputContextData[i]['parameters']['like_text']\n",
    "            \n",
    "        if 'ctx_dislike_text' in outputContextData[i]['name']:\n",
    "            dislike_text=outputContextData[i]['parameters']['dislike_text']\n",
    "                \n",
    "        if 'ctx_affinity_test' in outputContextData[i]['name']:\n",
    "            affinity_test_1=outputContextData[i]['parameters']['affinity_test_1']\n",
    "            affinity_test_2=outputContextData[i]['parameters']['affinity_test_2']\n",
    "    \n",
    "    sentiment_text=','.join([sentiment_text_1,sentiment_text_2,sentiment_text_3])\n",
    "    \n",
    "    \n",
    "    affinity_modifiers=affinity_tester(affinity_test_1,affinity_test_2)\n",
    "    \n",
    "    \n",
    "    return sentiment_text, affinity_modifiers, like_text, dislike_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this test implement the user's affinity to text review or composite rating. And select the modifier accordingly. \n",
    "def affinity_tester(affinity_test_1,affinity_test_2):\n",
    "    tally=0\n",
    "    try: \n",
    "        if int(affinity_test_1)==1:  #didn't deviate from user rating\n",
    "            tally+=0\n",
    "        elif int(affinity_test_1)!=1: #deviate from user rating\n",
    "            tally+=1\n",
    "        elif int(affinity_test_2)==5: #didn't deviate from user rating\n",
    "            tally+=0\n",
    "        else  :#int(affinity_test_2)!=1:#deviate from user rating.-> int(affinity_test_2)!=1\n",
    "            tally+=1\n",
    "    except:    \n",
    "        tally=tally #for invalied entries such as characters.\n",
    "    \n",
    "    if tally ==2:\n",
    "        return {'cs_ed_modifier': 0.0, 'semantic_modifier': 2.0} #biased towards semantic scoring\n",
    "    elif tally==0:\n",
    "        return {'cs_ed_modifier': 1.2, 'semantic_modifier': 0.8} #biased towards composite rating\n",
    "    else:\n",
    "        return {'cs_ed_modifier': 0.5, 'semantic_modifier': 1.5} #default neutral affinity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, os\n",
    "from PIL import Image\n",
    "def get_random_pictures():\n",
    "\n",
    "    a='https://aks7fg.ch.files.1drv.com/y4mr3c5LBrF9OF_Ngijwtyz5hi2gwNlVX5-67Ac-hOKb4tDuNadYTr1q4eLITKlgrFLGHJ3uXeKCzpeyt9lgWjIY2sfmORdtSgiT_pf6NLCunpHllzvTWvEXPlm0Z3l93MezBwYqNH5v7s5UjKTxgQ98iaPZtTKzl09nok5BTekeLRjAYDoxxlXF_MMymKQQNCvtwkN_KHFBGwG8sf85K6zsg?width=1080&height=1080&cropmode=none'\n",
    "    b='https://q6o7fg.ch.files.1drv.com/y4mOPATTNA1zIv9zF0ByGEqZT-30v0b12EW8sHOQifNwmYH7xn6C0RPo9GL8Drydtp4EirwVNW68IU_VVHDxw4q5W6aYeqe0QYjOspkydDaUjs_wxeLXVkBeKq_LPrcuQNbY5ZwGlRFsBo3oPRu54p8puq8yBR3Ge7I5b6q5WwT2ABfbzs76J8Bgl-dWCpWHzLoBh3TJYA-hnwoOfv4L1zRmQ?width=1080&height=1080&cropmode=none'\n",
    "    c='https://aqs7fg.ch.files.1drv.com/y4mJMBHiafy6ZZjoaBIIp1Fc-AsZR_2p6Ldg1KW6f6x9XvxZiQR4Xqdw4CMdXKSzeGsI3Ks6G40Y5_gZopZNlhb3yKVS11xmHwSpxZlmTIqxizbS5Na3vWt3gDkHelgidE5pYPeqZnloTORqdOoCHUMPJqTKw1c3EuW-OcO3lykQyTakyv6jBD8n6NGFtDw8b-z82gpabqzHVQjtAW8uVWXDw?width=1080&height=1080&cropmode=none'\n",
    "    d='https://bks7fg.ch.files.1drv.com/y4mHvzWl2Tr4VqHuw4BnOF47EvmYqu0_5f2ZCEjCsFNHmoB41egvRW0VTjy1N76XSANUSDdswW8N43HZdJs3EKJHw3K1UwFRQbpjiS1wdBHZj6XM-kTQ3MaULupZQPmpoIcVvn0ANeNRscXggcjI1Pgu28OqBYzreH7IiKrM9I3JHymF-M3rzGQ4Gm5l3C8woGJxyQKxjse44tf_TJDEQ-CPA?width=1080&height=1080&cropmode=none'\n",
    "    e='https://a6s7fg.ch.files.1drv.com/y4muOm3DZ5D-lczBAj1-VFi__e-_snfL6n72-jqxiFaVxCH4gIr5ZlwzDLhSxcEW5YMr-Z3jsL_CnvlxSRLpgDzHpfUXqtvyQItXpab5Otb1p5mx_vKoAFfUY6OlX2sidGVtE8FQrw7SUo4Qn_g72UyfUdTMefgQEhs5gcgUN3jXUrwS_eRa3NwCkPXtKt0Q8AxKyw2k3L7KUt9IBXJXgZQSQ?width=1080&height=1080&cropmode=none'\n",
    "    f='https://aas7fg.ch.files.1drv.com/y4mO_vjBM7VHLOqMOjsgu9EpHMlgB3WBdhCAhv0fsSTon56zDJSxeEsJQwp6-AWkRCj3VFidVEm568ILr1lCguLARJMlM30LwHVJqUtnj6QH34kbntmvUNzG_0zr7i3Fogsi3Kyr02o8p8zg1oSf70Lg2dNE5T75VqHMH2KxRrjgv50axPhlkrx8apiLCgjmg8xgN5dw5QjMz0mEDSho_Doxw?width=1080&height=1080&cropmode=none'\n",
    "\n",
    "    photo=[a,b,c,d,e,f]\n",
    "    return random.choice(photo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#randomly select photos of restaurants because actual database for real photos will be too large for this project. \n",
    "import random, os\n",
    "from PIL import Image\n",
    "def get_random_pictures():\n",
    "    #photo=random.choice([x for x in os.listdir(\"/users/KennethMacBookPro/Downloads/Capstone_Project/images\")\n",
    "    #           if os.path.isfile(os.path.join(\"/users/KennethMacBookPro/Downloads/Capstone_Project/images\", x))])\n",
    "    \n",
    "    #photopath=\"/users/KennethMacBookPro/Downloads/Capstone_Project/images/\"+photo\n",
    "    photo=random.choice([x for x in os.listdir(\"https://www.pythonanywhere.com/user/kenaimachine/files/home/kenaimachine/soulfood/images\")\n",
    "               if os.path.isfile(os.path.join(\"https://www.pythonanywhere.com/user/kenaimachine/files/home/kenaimachine/soulfood/images\", x))])\n",
    "    \n",
    "    photopath=\"https://www.pythonanywhere.com/user/kenaimachine/files/home/kenaimachine/soulfood/images\"+photo\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print (photopath)\n",
    "\n",
    "    #Image.open(\"/users/KennethMacBookPro/Downloads/Capstone Project/images/\"+photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender_Model:\n",
    "    def __init__(self):\n",
    "        self.df_restaurant_LA=pd.read_csv('/home/kenaimachine/soulfood/df_restaurant_LA_buildfinal.csv',low_memory=False)\n",
    "        #self.df_restaurantDetails=pd.read_csv('df_restaurantDetails.csv',low_memory=False)\n",
    "        self.loaded_rfc = pickle.load(open('/home/kenaimachine/soulfood/rfr_model_result.pkl', 'rb'))\n",
    "        self.doc2vecModel = pickle.load(open('/home/kenaimachine/soulfood/doc2vec_model.pkl', 'rb'))\n",
    "        self.doc2vec_featureMatrix = pickle.load(open('/home/kenaimachine/soulfood/doctovec_embeddings.pkl', 'rb'))\n",
    "\n",
    "                \n",
    "        self.df_LA_scaled=pd.DataFrame()\n",
    "        self.fullUserScore=pd.DataFrame()\n",
    "        self.analyser=SentimentIntensityAnalyzer()\n",
    "        \n",
    "        self.sentiment_cs_index=pd.DataFrame()\n",
    "        self.sentiment_ed_index=pd.DataFrame()\n",
    "        \n",
    "    def get_df_LA_scaled(self):\n",
    "        #scaling the relevant columns' data to reduce the the effect or some ratings skewing the cosine similiarity calculations.\n",
    "        selected_col=['stars_x','useful','stars_y_userMean','stars_y_userRating']\n",
    "        df_scaled=minmax_scale(self.df_restaurant_LA[selected_col])\n",
    "        \n",
    "        df_scaled=pd.DataFrame(df_scaled,columns=selected_col)\n",
    "        df_s=self.df_restaurant_LA[['negative','neutral','positive','compound']]\n",
    "        df_s\n",
    "       \n",
    "        self.df_LA_scaled=pd.concat([df_s,df_scaled], axis=1)\n",
    "        self.df_LA_scaled=self.df_LA_scaled[['stars_x','stars_y_userRating','useful','negative','neutral','positive','compound','stars_y_userMean']]\n",
    "        self.df_LA_scaled.head()\n",
    "        return self.df_LA_scaled\n",
    "    \n",
    "    #Use Sentiment Intensity Analyzer to get sentiment scores.\n",
    "    # return a result in dictionary form :{neg: _ , neu: _ ,pos: _ ,compound: _ }\n",
    "    def get_sentiment_scores(self,sentence):\n",
    "        #clear_output(wait=True)\n",
    "        return self.analyser.polarity_scores(sentence)\n",
    "    \n",
    "    def assemble_user_score(self,sentence):\n",
    "        bAvg_mean=self.df_LA_scaled['stars_x'].mean()\n",
    "        uAvg_mean=self.df_LA_scaled['stars_y_userMean'].mean()\n",
    "        useful_mean=self.df_LA_scaled['useful'].mean()\n",
    "        \n",
    "        #user_sentiment_score=get_sentiment_scores(sentence)\n",
    "        user_sentiment_score=sentence\n",
    "        #print(bAvg_mean,uAvg_mean, useful_mean, user_sentiment_score)\n",
    "        return bAvg_mean,uAvg_mean, useful_mean, user_sentiment_score\n",
    "    #drop stars_y_userRating because we are using Random Forest Classifier to predict the user rating. \n",
    "\n",
    "    def assemble_similarity_score(self,score):\n",
    "        bAvg_mean,uAvg_mean, useful_mean, user_sentiment_score=self.assemble_user_score(score)\n",
    "        df_userScore=pd.DataFrame(columns=['stars_x','useful','negative','neutral','positive','compound','stars_y_userMean'])\n",
    "        df_userScore.loc[0]={'stars_x':bAvg_mean,\n",
    "                             'useful':useful_mean,\n",
    "                             'negative':user_sentiment_score['neg'],\n",
    "                             'neutral':user_sentiment_score['neu'],\n",
    "                             'positive':user_sentiment_score['pos'],\n",
    "                             'compound':user_sentiment_score['compound'],\n",
    "                             'stars_y_userMean':uAvg_mean}\n",
    "        #print (df_userScore)\n",
    "        return df_userScore\n",
    "    \n",
    "    \n",
    "        \n",
    "    def get_fullUserScore(self,ass_Sim_scr,predict_stars_y):\n",
    "        predict_stars_y=pd.DataFrame(predict_stars_y,columns=['predict_stars_y'])\n",
    "        self.fullUserScore=pd.concat([ass_Sim_scr, predict_stars_y],axis=1)\n",
    "        return self.fullUserScore\n",
    "    \n",
    "    \n",
    "\n",
    "    def get_similarity(self,x):\n",
    "        df_y=self.df_LA_scaled[['stars_x','useful','negative','neutral','positive','compound','stars_y_userMean','stars_y_userRating']]\n",
    "\n",
    "        cosineSimilarity=cosine_similarity(x, df_y, dense_output=True)\n",
    "        euclideanDistance=euclidean_distances(x,df_y)\n",
    "        \n",
    "        cs=pd.DataFrame({'cosineSimilarity':cosineSimilarity.reshape(-1, )})\n",
    "        ed=pd.DataFrame({'euclideanDistance':euclideanDistance.reshape(-1, )})\n",
    "        \n",
    "\n",
    "        self.sentiment_cs_index=cs\n",
    "        \n",
    "        self.sentiment_ed_index=ed\n",
    "\n",
    "\n",
    "    \n",
    "    def get_randomForest_predict(self,assembledSimilarityScore):\n",
    "        result=self.loaded_rfc.predict([assembledSimilarityScore])\n",
    "        scaled_result=result/5\n",
    "        #print (scaled_result)\n",
    "        return scaled_result\n",
    "    \n",
    "    #starts a series of steps to retrieve restaurant data and prepare it for \n",
    "    #assembling into suitable format for fufillment response.\n",
    "    def view_recommendation(self, final_score):\n",
    "        final_score_index=final_score.index.values.astype(int)\n",
    "       # print (final_score_index)\n",
    "        \n",
    "        similarity_final_scoreList= final_score.values.tolist()\n",
    "        \n",
    "        telegram_data=self.restaurant_info(final_score_index,similarity_final_scoreList)\n",
    "        #telegram_data=self.restaurant_info([137359,99480])\n",
    "        reply=fulfillment_showRecommendation(telegram_data)\n",
    "        return reply\n",
    "        #for this test case, pass to fulfillment_showRecommendation()\n",
    "        #actual has to pass back to calling object.\n",
    "    \n",
    "    \n",
    "    #retrive the top 2 recommended restaurants' details.\n",
    "    def restaurant_info(self,final_score_index,similarity_final_scoreList):\n",
    "            telegram_data={'Card_1st':[],'Card_2nd':[]}\n",
    "\n",
    "            #telegram card can only show two cards.\n",
    "\n",
    "            for i, ind in enumerate(final_score_index):\n",
    "                address,name,stars_x,attributes,categories=self.get_restaurantDetails(ind)\n",
    "                rest_attributes=self.restaurant_attributes(attributes,categories)\n",
    "                if i==0:\n",
    "                    telegram_data['Card_1st']=[address,name,stars_x,rest_attributes,similarity_final_scoreList[0],ind]\n",
    "                    #print(telegram_data['Card_1st'])\n",
    "                else:\n",
    "                    telegram_data['Card_2nd']=[address,name,stars_x,rest_attributes,similarity_final_scoreList[1],ind]\n",
    "                    #print(telegram_data['Card_2nd'])\n",
    "            #print (telegram_data)\n",
    "            return telegram_data\n",
    "     \n",
    "    \n",
    "    #get the restaurants' 'attributes' column data. \n",
    "    #Data within this column can give the restaurant some useful descriptors.\n",
    "    def restaurant_attributes(self,attributes,categories):\n",
    "        attributesList=[]\n",
    "        \n",
    "        dictStr=ast.literal_eval(attributes)\n",
    "        dictStr_df=pd.DataFrame([dictStr])\n",
    "        #print (dictStr)\n",
    "        ambDictStr=dictStr_df.Ambience\n",
    "        #print (ambDictStr)\n",
    "        ads=ast.literal_eval(ambDictStr[0])\n",
    "        #print(ads)\n",
    "        for k,v in ads.items():\n",
    "            if v==True:\n",
    "                attributesList.append(k)\n",
    "            else:\n",
    "                None\n",
    "        #print (attributesList)\n",
    "        #print (dictStr_df.columns)\n",
    "        \n",
    "        #gFM=dictStr_df.GoodForMeal\n",
    "        try:\n",
    "            gFM=dictStr_df.GoodForMeal\n",
    "            g_FM=ast.literal_eval(gFM[0])\n",
    "            for k,v in g_FM.items():\n",
    "                    if v==True:\n",
    "                        attributesList.append(k)\n",
    "                    else:\n",
    "                        None\n",
    "        except:\n",
    "            None\n",
    "        \n",
    "        try:\n",
    "            bPk=dictStr_df.BusinessParking\n",
    "            BPK=ast.literal_eval(bPk[0])\n",
    "            for k,v in BPK.items():\n",
    "                    if v ==True:\n",
    "                        k='Business Parking :'+str(k)\n",
    "                        attributesList.append(k)\n",
    "                    else:\n",
    "                        None    \n",
    "        except:\n",
    "            None\n",
    "            attributesList.append(categories)\n",
    "        return ','.join(attributesList)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    #mainline logic within the Recommendation_model class.\n",
    "    #message_list= [sentiment_text, affinity_modifiers, like_text, dislike_text] - for reference during coding\n",
    "    def query_recommendation_model(self,message_list):\n",
    "        self.get_df_LA_scaled()\n",
    "        message = ','.join(message_list[2:])\n",
    "        \n",
    "        mood_today=self.get_sentiment_scores(message_list[0])\n",
    "        dissimilarity_modifier=self.sentiment_text_tester(mood_today) #to modify dissimilarity strictness level.\n",
    "        \n",
    "        score=self.get_sentiment_scores(message)\n",
    "        #print (score)\n",
    "        #print (assemble_similarity_score(score))\n",
    "        ass_Sim_scr=self.assemble_similarity_score(score)\n",
    "        ass_Sim_scr_ravel=ass_Sim_scr.values.ravel()\n",
    "        predict_stars_y=self.get_randomForest_predict(ass_Sim_scr_ravel)\n",
    "        fullUserScore=self.get_fullUserScore(ass_Sim_scr,predict_stars_y)\n",
    "        print('Full User Score (scaled): \\n',fullUserScore)\n",
    "        self.get_similarity(fullUserScore)\n",
    "        \n",
    "        #semantic similarity score \n",
    "        #like_message, dislike_message= self.get_message_sentiment(message)\n",
    "        \n",
    "        like1,dislike1= self.get_message_sentiment(message_list[2])\n",
    "        like2,dislike2= self.get_message_sentiment(message_list[3])\n",
    "        \n",
    "        like_message=','.join([like1,like2])\n",
    "        dislike_message=','.join([dislike1,dislike2])\n",
    "        \n",
    "        ##query_recommendation_model needs parameters like_message and dislike_message\n",
    "        similar_taste = self.get_semantic_similarity_scores(like_message)\n",
    "        dissimilar_taste = self.get_dissimilarity_scores(dislike_message)\n",
    "        \n",
    "        print ('\\nSemantic Similarity Score :\\n',similar_taste.sort_values(by=['cosine_similarity_semantic'],ascending=False).head())\n",
    "        print ('\\nDissimilarity Score :\\n',dissimilar_taste.sort_values(by=['dissimilarity'],ascending=False).head())\n",
    "\n",
    "\n",
    "        #design decision to set cosine similarity score greater than 0.1 as dissimilar.\n",
    "\n",
    "        #dissimilar_taste = dissimilar_taste.query('dissimilarity > .1')\n",
    "        #similar_taste = similar_taste.drop(dissimilar_taste.index)\n",
    "        final_score=self.ensemble_similarity(message_list,\n",
    "                                             similar_taste,\n",
    "                                             dissimilar_taste,\n",
    "                                             dissimilarity_modifier)\n",
    "        \n",
    "        \n",
    "        #print ('Top 10 Ensemble Similarity Scores :',final_score[0:10])\n",
    "        final_score=self.check_sameRestaurant(final_score[0:6])\n",
    "        print ('Index, Similarity score, name:\\n',final_score)\n",
    "        \n",
    "        reply=self.view_recommendation(final_score[0:2]) #only top 2 results are recommended.\n",
    "        \n",
    "        return reply\n",
    "        \n",
    "    \n",
    "    \n",
    "        #clean text\n",
    "    def stem_words(self,text):\n",
    "        text = text.split()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        text = \" \".join(stemmed_words)\n",
    "        return text\n",
    "\n",
    "    def make_lower_case(self,text):\n",
    "        return text.lower()\n",
    "\n",
    "    def remove_stop_words(self,text):\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "        return text\n",
    "\n",
    "    def remove_punctuation(self,text):\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        text = tokenizer.tokenize(text)\n",
    "        text = \" \".join(text)\n",
    "        return text\n",
    "    \n",
    "    def clean_user_message(self, message):\n",
    "        message=self.make_lower_case(message)\n",
    "        message =self.remove_stop_words(message)\n",
    "        message=self.remove_punctuation(message)\n",
    "        message=self.stem_words(message)\n",
    "        return message\n",
    "    \n",
    "    #infer vector of the user message using doc2vec model.\n",
    "    def get_message_doc2vec_embedding_vector(self,message):\n",
    "        message_array = self.doc2vecModel.infer_vector(doc_words=message.split(\" \"), epochs=200)\n",
    "        message_array = message_array.reshape(1, -1)\n",
    "        return message_array\n",
    "    \n",
    "    \n",
    "    def get_semantic_similarity_scores(self, message):\n",
    "        message = self.clean_user_message(message)\n",
    "        \n",
    "        semantic_message_array = self.get_message_doc2vec_embedding_vector(message)\n",
    "        \n",
    "        semantic_similarity = self.get_similarity_scores(semantic_message_array, self.doc2vec_featureMatrix)\n",
    "        \n",
    "        #don't sort.\n",
    "        #semantic_similarity.sort_values(by=\"cosine_similarity\", ascending=False, inplace=True)\n",
    "        \n",
    "        #print ('Semantic Similarity Score',semantic_similarity)\n",
    "        return semantic_similarity\n",
    "    \n",
    "    \n",
    "    #calculate the similiary score using cosine similarity compared against the \n",
    "    #doc2vec_trained featureMatix. This was trained previously using exisitng text review.\n",
    "    def get_similarity_scores(self,message_array, embeddings):\n",
    "        cosine_sim_matrix = pd.DataFrame(cosine_similarity(X=embeddings,\n",
    "                                                           Y=message_array,\n",
    "                                                           dense_output=True))\n",
    "        cosine_sim_matrix.set_index(embeddings.index, inplace=True)\n",
    "        cosine_sim_matrix.columns = [\"cosine_similarity_semantic\"]\n",
    "        \n",
    "        return cosine_sim_matrix\n",
    "    \n",
    "    #similiar thinkin as get_similarity_scores except it's applied to get dissimilarity. \n",
    "    def get_dissimilarity_scores(self, message):\n",
    "        message = self.clean_user_message(message)\n",
    "        semantic_message_array = self.get_message_doc2vec_embedding_vector(message)\n",
    "\n",
    "        dissimilarity = self.get_similarity_scores(semantic_message_array, self.doc2vec_featureMatrix)\n",
    "        dissimilarity.columns = [\"dissimilarity\"]\n",
    "        \n",
    "        #dissimilarity.sort_values(by=\"dissimilarity\", ascending=False, inplace=True)\n",
    "        return dissimilarity\n",
    "    \n",
    "    \n",
    "    #cleans up and user text input and tease out the like and dislike message from sentiment score. \n",
    "    def get_message_sentiment(self, message):\n",
    "        sentences=re.split(r'\\s+',re.sub(r'\\W+',\" \",message))\n",
    "        sentences = [x for x in sentences if x != \"\"]\n",
    "        like_message = \"\"\n",
    "        dislike_message = \"\"\n",
    "        for s in sentences:\n",
    "            sentiment_scores = self.get_sentiment_scores(s)\n",
    "            if sentiment_scores['neg'] > 0:\n",
    "                dislike_message = dislike_message + s\n",
    "            else:\n",
    "                like_message = like_message + s\n",
    "        return like_message, dislike_message\n",
    "    \n",
    "    \n",
    "    #this function adjust the dissimilarity modifier which restrict datasets used to compute similarity between users. \n",
    "    def sentiment_text_tester(self,mood_today):\n",
    "    \n",
    "        if float(mood_today['compound'])>=0.05: #when mood is good, we relaxed the recommendation so user can explore.\n",
    "            dissimilarity_modifier=0.007\n",
    "        elif float(mood_today['compound'])<=-0.05: #when mood is bad, we are stricter with negative recommendation.\n",
    "            dissimilarity_modifier=0.003\n",
    "        else:\n",
    "            dissimilarity_modifier=0.005  #default value\n",
    "        return dissimilarity_modifier\n",
    "    \n",
    "    \n",
    "    #calculate the ensemble similiarity score with the modifiers.\n",
    "    # 2 modifiers are used: dissimilarity modifer, and\n",
    "    #message_list[1], which is an affinity modifier in dictionary forma \n",
    "    #which modifies the weightage between \n",
    "    #composite ratings biasedness or semantic biasedness. \n",
    "    def ensemble_similarity(self,message_list,similiar_taste, dissimilar_taste,dissimilarity_modifier):\n",
    "        \n",
    "        \n",
    "        #merge cosine similarity, euclidean distance, similar_taste and dissimilar_taste intoe one dataframe.\n",
    "        df_ensemble_similarity_score=pd.merge(self.sentiment_cs_index,self.sentiment_ed_index, right_index=True, left_index=True)\n",
    "        df_ensemble_similarity_score=pd.merge(df_ensemble_similarity_score,similiar_taste, right_index=True, left_index=True)\n",
    "        df_ensemble_similarity_score=pd.merge(df_ensemble_similarity_score,dissimilar_taste, right_index=True, left_index=True)\n",
    "        \n",
    "        dissimilarity_modifier= ' > '.join(['dissimilarity',str(dissimilarity_modifier)])\n",
    "        dissimilar_taste_ind = df_ensemble_similarity_score.query(dissimilarity_modifier)\n",
    "\n",
    "        df_ensemble_similarity_score = df_ensemble_similarity_score.drop(dissimilar_taste_ind.index)\n",
    "        \n",
    "        a=message_list[1]['cs_ed_modifier']\n",
    "        b=message_list[1]['semantic_modifier']\n",
    "        \n",
    "        #the following print statements are to visualise the modifiers. \n",
    "        print ('\\ndissimilarity_modifier :',dissimilarity_modifier)\n",
    "        print ('\\ncs_ed_modifier :',a)\n",
    "        print('\\nsemantic_modifier :',b)\n",
    "        \n",
    "        #we are looking at relative similarity. So similarity score just implies relative sameness or difference\n",
    "        #it does not imply any relationship between the numbers. ie. 0.8 is not 2x more similar than 0.4. \n",
    "        #for similarity score which were previously negative, minmax_scale will tranform to positive or zero.\n",
    "        #this does not affect ranking performance because the value will rank lower.    \n",
    "        df_ensemble_similarity_score['cosineSimilarity']=minmax_scale(df_ensemble_similarity_score['cosineSimilarity'])\n",
    "        df_ensemble_similarity_score['euclideanDistance']=minmax_scale(df_ensemble_similarity_score['euclideanDistance'])\n",
    "        df_ensemble_similarity_score['cosine_similarity_semantic']=minmax_scale(df_ensemble_similarity_score['cosine_similarity_semantic'])\n",
    "\n",
    "        #print(\"df_ensemble_similarity_score['cosineSimilarity'] :\\n:\",df_ensemble_similarity_score['cosineSimilarity'].max(), df_ensemble_similarity_score['cosineSimilarity'].min())\n",
    "        #print (\"df_ensemble_similarity_score['euclideanDistance'] :\\n\",df_ensemble_similarity_score['euclideanDistance'].max(),df_ensemble_similarity_score['euclideanDistance'].min())\n",
    "        #print (\"df_ensemble_similarity_score['cosine_similarity_semantic'] :\\n\",df_ensemble_similarity_score['cosine_similarity_semantic'].max(),df_ensemble_similarity_score['cosine_similarity_semantic'].min())\n",
    "        \n",
    "        df_ensemble_similarity_score=((df_ensemble_similarity_score['cosineSimilarity']+df_ensemble_similarity_score['euclideanDistance'])*a/2+df_ensemble_similarity_score['cosine_similarity_semantic']*b)/2\n",
    "        df_ensemble_similarity_score=pd.DataFrame({'Complete_Similarity_Score': df_ensemble_similarity_score})\n",
    "        \n",
    "        \n",
    "        df_ensemble_similarity_score.sort_values(by=\"Complete_Similarity_Score\", ascending=False, inplace=True)\n",
    "        print ('\\ndf_ensemble_similarity_score :\\n',df_ensemble_similarity_score[0:5])\n",
    "        return df_ensemble_similarity_score\n",
    "    \n",
    "    \n",
    "    def create_connection(self,db_file):\n",
    "        \"\"\" create a database connection to the SQLite database\n",
    "            specified by the db_file\n",
    "        :param db_file: database file\n",
    "        :return: Connection object or None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(db_file)\n",
    "            return conn\n",
    "        except Error as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    def get_restaurantDetails(self,final_score_index):\n",
    "        #final_score_index parameter must be passed in as just one integer value.\n",
    "        sql='''\n",
    "            SELECT address, name, stars_x, attributes, categories  \n",
    "            FROM restaurant_details\n",
    "            WHERE restaurant_details.id=='''+str(final_score_index)\n",
    "            \n",
    "\n",
    "\n",
    "        database = \"/home/kenaimachine/soulfood/restaurants.db\"\n",
    "        conn = self.create_connection(database)\n",
    "        with conn:\n",
    "            cur = conn.cursor()\n",
    "            cur.execute(sql)\n",
    "            row = cur.fetchall()\n",
    "            #print(row)\n",
    "            \n",
    "        address=row[0][0]\n",
    "        name=row[0][1]\n",
    "        stars_x=row[0][2]\n",
    "        attributes=row[0][3]\n",
    "        categories=row[0][4]\n",
    "            \n",
    "            #print (address)\n",
    "            #print (name)\n",
    "            #print (stars_x)\n",
    "            #print(attributes)\n",
    "            #print (categories)\n",
    "\n",
    "\n",
    "        return address,name,stars_x,attributes,categories\n",
    "    \n",
    "    def check_sameRestaurant(self, final_score):\n",
    "        final_score_index=final_score.index.values\n",
    "        name_list=[]\n",
    "        for i in final_score_index:\n",
    "            sql=\"SELECT name FROM restaurant_details WHERE restaurant_details.id==\"+str(i)\n",
    "            database = \"/home/kenaimachine/soulfood/restaurants.db\"\n",
    "            conn = self.create_connection(database)\n",
    "            with conn:\n",
    "                cur = conn.cursor()\n",
    "                cur.execute(sql)\n",
    "                row = cur.fetchall()\n",
    "                name=row[0]\n",
    "                name_list.append(name)\n",
    "        \n",
    "        final_score['name']=name_list\n",
    "        final_score=final_score.drop_duplicates(subset='name',keep='first')\n",
    "        #final_score df with col index,similarityscore,name\n",
    "        return final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#get the photo link -method 2\n",
    "#for example name: telegram_data['Card_1st'][1]\n",
    "#http://kenaimachine.pythonanywhere.com/static/-1nmjnrNUcmbjYVmlqpkYQ.jpg\n",
    "\n",
    "def get_photos(row_number):\n",
    "    df_restaurant_LA=df_=pd.read_csv('/home/kenaimachine/soulfood/df_restaurant_LA_buildfinal.csv',low_memory=False)\n",
    "    data_df=pd.read_csv('/home/kenaimachine/soulfood/photos.csv',low_memory=False)\n",
    "\n",
    "    photo_id=business_picker(row_number, df_restaurant_LA,data_df)\n",
    "    return 'http://kenaimachine.pythonanywhere.com/static/'+photo_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def business_picker (row_number,df_restaurant_LA, data_df):\n",
    "    #print (df_restaurant_LA.index==row_number)\n",
    "    a=df_restaurant_LA.loc[df_restaurant_LA.index==row_number, 'business_id']\n",
    "    \n",
    "    return photo_picker(a[row_number],data_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def photo_picker(id, data_df):\n",
    "    a=data_df[data_df.loc[:,'business_id']==id]\n",
    "    b=a.loc[a.loc[:,'label']=='outside','photo_id']\n",
    "    c=b.reset_index()\n",
    "    return c.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile and format the required fulfillment messages for dialogflow. \n",
    "def fulfillment_showRecommendation(telegram_data):\n",
    "    #telegram_data={'Card_1st':[address,name,stars_x,rest_attributes,similarity_final_scoreList[0],rowindex_1],'Card_2nd':[address,name,stars_x,rest_attributes,similarity_final_scoreList[1],rowindex_2]}\n",
    "    #print (type(telegram_data['Card_1st'][0]), type(telegram_data['Card_1st'][3]), type(str(telegram_data['Card_1st'][2])))\n",
    "    #print ('fulfillment_showRecommendation :',telegram_data)\n",
    "    \n",
    "    reply={}\n",
    "    reply[\"fulfillmentText\"]=\" \"\n",
    "    reply[\"fulfillmentMessages\"]= [\n",
    "             {\n",
    "        \"text\": {\n",
    "          \"text\": [\n",
    "            \"Thanks for waiting. Here's my recommendations:\"\n",
    "          ]\n",
    "        },\n",
    "        \"platform\": \"TELEGRAM\"\n",
    "      },\n",
    "      {\n",
    "        \"card\": {\n",
    "          \"title\": telegram_data['Card_1st'][1],\n",
    "          \"subtitle\": ' '.join([telegram_data['Card_1st'][0], telegram_data['Card_1st'][3], ' Average Rating :', str(telegram_data['Card_1st'][2]), ' Similarity :', str(telegram_data['Card_1st'][4][0])]),\n",
    "          \"imageUri\": get_random_pictures(),#get_photos(telegram_data['Card_1st'][5]),\n",
    "          \"buttons\":[\n",
    "                      {\n",
    "                        \"text\": 'https://www.yelp.com/search?find_desc='+ telegram_data['Card_1st'][1]+'&find_loc=Las%20Vegas%2C%20NV%2C%20United%20States&ns=1&cflt=restaurants'\n",
    "                      }\n",
    "                     \n",
    "                      ]\n",
    "            \n",
    "        },\n",
    "        \"platform\": \"TELEGRAM\"\n",
    "      },\n",
    "      {\n",
    "        \"card\": {\n",
    "          \"title\": telegram_data['Card_2nd'][1],\n",
    "          \"subtitle\": ' '.join([telegram_data['Card_2nd'][0], telegram_data['Card_2nd'][3], ' Average Rating :', str(telegram_data['Card_2nd'][2]), 'Similarity :',str(telegram_data['Card_2nd'][4][0])]),\n",
    "          \"imageUri\": get_random_pictures(),\n",
    "          \"buttons\":[\n",
    "                      {\n",
    "                        \"text\": 'https://www.yelp.com/search?find_desc='+ telegram_data['Card_2nd'][1]+'&find_loc=Las%20Vegas%2C%20NV%2C%20United%20States&ns=1&cflt=restaurants'\n",
    "                      }\n",
    "                     \n",
    "                      ]\n",
    "            \n",
    "            \n",
    "        },\n",
    "        \"platform\": \"TELEGRAM\"\n",
    "      },\n",
    "      {\n",
    "        \"text\": {\n",
    "          \"text\": [\n",
    "            \"I hoped you like the two recommendations. Have a great day! To restart, type /restart.\"\n",
    "          ]\n",
    "        },\n",
    "        \"platform\": \"TELEGRAM\"\n",
    "      }\n",
    "        \n",
    "        ]\n",
    "    \n",
    "    #print (reply)\n",
    "    return reply\n",
    "    ##return jsonify(reply)    \n",
    "\n",
    "    #require, title, subtitle, imageUrl, button text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#compile and format the required fulfillment messages for dialogflow. \n",
    "def fulfillment_showRecommendation(telegram_data):\n",
    "    #telegram_data={'Card_1st':[address,name,stars_x,rest_attributes],'Card_2nd':[address,name,stars_x,rest_attributes]}\n",
    "    #print (type(telegram_data['Card_1st'][0]), type(telegram_data['Card_1st'][3]), type(str(telegram_data['Card_1st'][2])))\n",
    "    #print ('fulfillment_showRecommendation :',telegram_data)\n",
    "    \n",
    "    reply={}\n",
    "    reply[\"fulfillmentText\"]=\" \"\n",
    "    reply[\"fulfillmentMessages\"]= [\n",
    "            {\n",
    "                \"text\": {\n",
    "                  \"text\": [\n",
    "                    \"Thanks for waiting. After careful analysis, I am giving you top two recommendations. Please see below:\"\n",
    "                  ]\n",
    "                },\n",
    "                \"platform\": \"TELEGRAM\"\n",
    "              },\n",
    "            { \n",
    "                \n",
    "              \"card\" : {\n",
    "                  \"title\":telegram_data['Card_1st'][1],\n",
    "                  \"subtitle\":' '.join([telegram_data['Card_1st'][0], telegram_data['Card_1st'][3], ' Average Rating :', str(telegram_data['Card_1st'][2])]),\n",
    "                  \"imageUrl\": get_random_pictures(),\n",
    "                  \"buttons\":[\n",
    "                      {\n",
    "                        \"text\": 'https://www.yelp.com/search?find_desc='+ telegram_data['Card_1st'][1]+'&find_loc=Las%20Vegas%2C%20NV%2C%20United%20States&ns=1&cflt=restaurants'\n",
    "                      }\n",
    "                     \n",
    "                      ]\n",
    "                  },\n",
    "                \"platform\":\"TELEGRAM\"\n",
    "            },\n",
    "            {\n",
    "            \"card\" : {\n",
    "                  \"title\":telegram_data['Card_2nd'][1],\n",
    "                  \"subtitle\":' '.join([telegram_data['Card_2nd'][0], telegram_data['Card_2nd'][3], ' Average Rating :', str(telegram_data['Card_2nd'][2])]),\n",
    "                  \"imageUrl\": get_random_pictures(),\n",
    "                  \"buttons\":[\n",
    "                      {\n",
    "                        \"text\": 'https://www.yelp.com/search?find_desc='+ telegram_data['Card_2nd'][1]+'&find_loc=Las%20Vegas%2C%20NV%2C%20United%20States&ns=1&cflt=restaurants'\n",
    "                      }\n",
    "                     \n",
    "                      ]\n",
    "                  },\n",
    "            \"platform\":\"TELEGRAM\"\n",
    "            }\n",
    "        \n",
    "        ]\n",
    "    \n",
    "    #print (reply)\n",
    "    return reply\n",
    "    ##return jsonify(reply)    \n",
    "\n",
    "    #require, title, subtitle, imageUrl, button text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Tip: There are .env files present. Do \"pip install python-dotenv\" to use them.\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#tester\n",
    "sentiment_text_1='hello u'\n",
    "sentiment_text_2='gd bye'\n",
    "sentiment_text_3='abc, def'\n",
    "sentiment_text_4=[sentiment_text_1,sentiment_text_2,sentiment_text_3]\n",
    "\n",
    "sentiment_text=','.join([sentiment_text_1,sentiment_text_2,sentiment_text_3])\n",
    "print (sentiment_text, type(sentiment_text))\n",
    "message = ','.join(sentiment_text_4[1:])\n",
    "print (message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#tester\n",
    "import random, os\n",
    "from PIL import Image\n",
    "photo=random.choice([x for x in os.listdir(\"/users/KennethMacBookPro/Downloads/Capstone Project/images\")\n",
    "               if os.path.isfile(os.path.join(\"/users/KennethMacBookPro/Downloads/Capstone Project/images\", x))])\n",
    "#print (photo)\n",
    "\n",
    "Image.open(\"/users/KennethMacBookPro/Downloads/Capstone Project/images/\"+photo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#For testing purposes. \n",
    "data={\n",
    "  \"responseId\": \"1d0decfd-76ec-4c3c-8a02-4fd0442a265c-b55300fa\",\n",
    "  \"queryResult\": {\n",
    "    \"queryText\": \"ok\",\n",
    "    \"action\": \"get_tasks\",\n",
    "    \"parameters\": {},\n",
    "    \"allRequiredParamsPresent\": True,\n",
    "    \"fulfillmentMessages\": [\n",
    "      {\n",
    "        \"text\": {\n",
    "          \"text\": [\n",
    "            \"\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"outputContexts\": [\n",
    "      {\n",
    "        \"name\": \"projects/restaurant-recommender-duusew/agent/sessions/12418c30-10f7-9e44-9526-d63f2cbaf759/contexts/ctx_like_text\",\n",
    "        \"lifespanCount\": 5,\n",
    "        \"parameters\": {\n",
    "          \"like_text.original\": \"like pizza\",\n",
    "          \"dislike_text.original\": \"dislike burgers\",\n",
    "          \"like_text\": \"like pizza\",\n",
    "          \"dislike_text\": \"dislike burgers\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"projects/restaurant-recommender-duusew/agent/sessions/12418c30-10f7-9e44-9526-d63f2cbaf759/contexts/ctx_dislike_text\",\n",
    "        \"lifespanCount\": 5,\n",
    "        \"parameters\": {\n",
    "          \"dislike_text.original\": \"dislike burgers\",\n",
    "          \"dislike_text\": \"dislike burgers\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"projects/restaurant-recommender-duusew/agent/sessions/12418c30-10f7-9e44-9526-d63f2cbaf759/contexts/ctx_affinity_test\",\n",
    "        \"lifespanCount\": 5,\n",
    "        \"parameters\": {\n",
    "          \"dislike_text.original\": \"dislike burgers\",\n",
    "          \"like_text\": \"like pizza\",\n",
    "          \"affinity_test_1.original\": \"1\",\n",
    "          \"like_text.original\": \"like pizza\",\n",
    "          \"affinity_test_1\": \"1\",\n",
    "          \"affinity_test_2.original\": \"5\",\n",
    "          \"dislike_text\": \"dislike burgers\",\n",
    "          \"affinity_test_2\": \"5\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"projects/restaurant-recommender-duusew/agent/sessions/12418c30-10f7-9e44-9526-d63f2cbaf759/contexts/ctx_sentiment_text\",\n",
    "        \"lifespanCount\": 5,\n",
    "        \"parameters\": {\n",
    "          \"sentiment_text_3\": \"cheerful\",\n",
    "          \"affinity_test_1\": \"1\",\n",
    "          \"affinity_test_2\": \"5\",\n",
    "          \"like_text\": \"like pizza\",\n",
    "          \"sentiment_text_1.original\": \"happy\",\n",
    "          \"affinity_test_1.original\": \"1\",\n",
    "          \"sentiment_text_1\": \"cheerful\",\n",
    "          \"like_text.original\": \"like pizza\",\n",
    "          \"sentiment_text_3.original\": \"happy\",\n",
    "          \"affinity_test_2.original\": \"5\",\n",
    "          \"dislike_text\": \"dislike burgers\",\n",
    "          \"sentiment_text_2\": \"cheerful\",\n",
    "          \"sentiment_text_2.original\": \"happy\",\n",
    "          \"dislike_text.original\": \"dislike burgers\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"projects/restaurant-recommender-duusew/agent/sessions/12418c30-10f7-9e44-9526-d63f2cbaf759/contexts/asktoproceed\",\n",
    "        \"lifespanCount\": 5,\n",
    "        \"parameters\": {\n",
    "          \"dislike_text.original\": \"dislike burgers\",\n",
    "          \"dislike_text\": \"dislike burgers\"\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"intent\": {\n",
    "      \"name\": \"projects/restaurant-recommender-duusew/agent/intents/807ddd54-370f-49a3-b1f4-6ce60f8bde5f\",\n",
    "      \"displayName\": \"MakeRecommendations\"\n",
    "    },\n",
    "    \"intentDetectionConfidence\": 1,\n",
    "    \"diagnosticInfo\": {\n",
    "      \"webhook_latency_ms\": 607\n",
    "    },\n",
    "    \"languageCode\": \"en\"\n",
    "  },\n",
    "  \"webhookStatus\": {\n",
    "    \"code\": 13,\n",
    "    \"message\": \"Webhook call failed. Error: 500 Internal Server Error.\"\n",
    "  }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#for testing only\n",
    "get_tasks(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def on_button_clicked(b):\n",
    "    clear_output()\n",
    "    print (\"Describe the restaurant experience you are looking for. You can be as detailed as you like! \")\n",
    "    display(text)\n",
    "    display(button)\n",
    "     \n",
    "\n",
    "def handle_submit(sender):\n",
    "    print (\"Got it! Hold tight while I find your recommendations!\")\n",
    "    message = sender.value\n",
    "    rm.query_recommendation_model(message)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rm=Recommender_Model()\n",
    "print (\"Describe the restaurant experience you are looking for. You can be as detailed as you like!\\n\\\n",
    "Type In The Box Provided And Press Enter To Submit:\")\n",
    "text = widgets.Text()\n",
    "display(text)\n",
    "button = widgets.Button(description=\"Restart!\")\n",
    "display(button)\n",
    "\n",
    "\n",
    "text.on_submit(handle_submit)\n",
    "button.on_click(on_button_clicked)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
